{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count motif occurrences across datasets and generate tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently than MutSplice pipeline, that targeted motif of the RBP of interest, we now scan all motifs over all paired datasets to generate motif occurrences that can be used for machine learning. In addition, we also generate tabular datasets of k-mer-based occurrences, which serves as a unbiased approach to distinguish exon groups based on patterns found in sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(font_scale=1)\n",
    "from plotnine import *\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import glob\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "tqdm.pandas()\n",
    "from mutsplice.datasets.tabular_dataset import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRED_DATASETS = pd.read_csv(\"/home/pbarbosa/git_repos/mutsplice/data/2_paired_datasets/ALL_data.tsv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLICEAI_PREDS = pd.read_csv(\"/home/pbarbosa/git_repos/mutsplice/notebooks/1_SpliceAI/4_datasets/encode_sequences_fixed_at_5000bp_output.tsv.gz\", sep=\"\\t\")\n",
    "SPLICEAI_PREDS['pred'] = SPLICEAI_PREDS[['ref_donor_cassette', 'ref_acceptor_cassette']].mean(axis=1)\n",
    "SPLICEAI_PREDS['transcript_id'] = SPLICEAI_PREDS.seq_id.str.split(\"_\").str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtfhandle.utils import file_to_bed_df\n",
    "from mutsplice.datasets.mutsplice_pipeline import MutSplicePipeline\n",
    "\n",
    "def runMutSplice_justMotifScan(df, rbp_name: str, exon_group: str, motif_source: str, motif_search: str):\n",
    "    GTF_CACHE = \"/home/pbarbosa/data/genomes/hg38/gtf_cache_gencode/\"\n",
    "    OUT_DIR = f\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/{rbp_name}/\"\n",
    "    FASTA = \"/home/pbarbosa/data/genomes/hg38/GRCh38.primary_assembly.genome.fa\"\n",
    "\n",
    "    kwargs = {\n",
    "        \"gtf_cache\": GTF_CACHE,\n",
    "        \"fasta\": FASTA,\n",
    "        \"out_dir\": f\"{OUT_DIR}{exon_group}\",\n",
    "        \"outbasename\": f\"{rbp_name}\",\n",
    "        \"subset_rbps\": \"encode\",\n",
    "        \"motif_source\": motif_source,\n",
    "        \"motif_search\": motif_search,\n",
    "        \"pvalue_threshold\": 0.0001,\n",
    "        \"min_nuc_probability\": 0.15,\n",
    "        \"use_full_sequence\": False,\n",
    "        \"spliceai_final_results\": None\n",
    "    }\n",
    "    bed_df = file_to_bed_df(df, is_0_based=False, header=0, col_index=0)\n",
    "\n",
    "    MutSplicePipeline(\n",
    "        bed_df,\n",
    "        do_gtf_queries=True,\n",
    "        do_motif_scanning=True,\n",
    "        do_mutations=False,\n",
    "        run_spliceai=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_single_RBP(group, exon_group: str, motif_source: str, motif_search: str):\n",
    "    try:\n",
    "        rbp_name = group.iloc[0].rbp_name\n",
    "        runMutSplice_justMotifScan(\n",
    "            group,\n",
    "            rbp_name=rbp_name,\n",
    "            exon_group=exon_group,\n",
    "            motif_source=motif_source,\n",
    "            motif_search=motif_search,\n",
    "        )\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Caught ValueError for {rbp_name}: {ve}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knockdown exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KD_data = PAIRED_DATASETS[PAIRED_DATASETS.exon_group == \"KD\"]\n",
    "KD_data.groupby(\"rbp_name\").apply(\n",
    "    process_single_RBP, exon_group=\"KD\", motif_source=\"ATtRACT\", motif_search=\"fimo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctrl_data = PAIRED_DATASETS[PAIRED_DATASETS.exon_group == \"CTRL\"]\n",
    "Ctrl_data.groupby(\"rbp_name\").apply(\n",
    "    process_single_RBP,\n",
    "    exon_group=\"CTRL\",\n",
    "    motif_source=\"ATtRACT\",\n",
    "    motif_search=\"fimo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on motif occurrences (total and per location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_on = ['target_coordinates', 'transcript_id']\n",
    "PAIRED_DATASETS = PAIRED_DATASETS.merge(SPLICEAI_PREDS, on=merge_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'subset_rbps': 'encode_in_attract', \n",
    "          'motif_source': 'attract'}\n",
    "rbp_dirs = (os.listdir(\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/\"))\n",
    "cols_to_drop = [\"pred\", \"transcript_id\", \"Strand\", \"gene_name\", \"paired_with\"]\n",
    "to_drop_ending_with = [\"downstream_2\", \"upstream_2\", \"upstream2\", \"downstream2\"]\n",
    "to_drop_starting_with = [\"ref_acceptor\", \"ref_donor\"]\n",
    "\n",
    "for rbp in rbp_dirs:\n",
    "    _dir = f\"4_all_motifScan/{rbp}\"\n",
    "\n",
    "    data_kd = PAIRED_DATASETS[(PAIRED_DATASETS.rbp_name == rbp) & (PAIRED_DATASETS.exon_group == \"KD\")]\n",
    "    data_ctrl = PAIRED_DATASETS[(PAIRED_DATASETS.rbp_name == rbp) & (PAIRED_DATASETS.exon_group == \"CTRL\")]\n",
    "\n",
    "    for granularity, tag in {'motif': 'motifs', 'per_location': 'motifs_per_loc'}.items():\n",
    "        out = []\n",
    "    \n",
    "        for g_name, _data in {\"KD\": data_kd, \"CTRL\": data_ctrl}.items():\n",
    "        \n",
    "            td = TabularDataset(_data, \n",
    "                outdir=f\"{_dir}/{g_name}\", \n",
    "                granularity=granularity,\n",
    "                normalize_by_length=True,\n",
    "                **kwargs)\n",
    "            \n",
    "            td.data = td.data.drop(columns=cols_to_drop)\n",
    "            cols_to_keep = [col for col in td.data.columns if not any([col.endswith(ending) for ending in to_drop_ending_with]) and not any([col.startswith(start) for start in to_drop_starting_with])]\n",
    "            td.data = td.data[cols_to_keep]\n",
    "            out.append(td.data)\n",
    "        \n",
    "        df = pd.concat(out)\n",
    "        df.rename(columns={'average_cassette_strength': 'spliceai_pred'}, inplace=True)\n",
    "        cols = df.columns.tolist()\n",
    "        cols_to_move = ['exon_group', 'dPSI', 'spliceai_pred']\n",
    "        cols = [col for col in cols if col not in cols_to_move] + cols_to_move\n",
    "        df = df[cols]\n",
    "        df.to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_{tag}.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on k-mer occurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtfhandle.utils import fasta_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trim_seq(row, ss_df):\n",
    "    ss_idx = ss_df[ss_df.seq_id == row.seq_id].iloc[0]\n",
    "    start = ss_idx.acceptor_idx.split(\";\")[0]\n",
    "    if start == \"<NA>\":\n",
    "        start = 0\n",
    "    else:\n",
    "        start = int(start)\n",
    "    end = ss_idx.donor_idx.split(\";\")[2]\n",
    "    if end == \"<NA>\":\n",
    "        end = len(row.sequence)\n",
    "    else:\n",
    "        end = int(end)\n",
    "    \n",
    "    row['sequence'] = row['sequence'][start:end]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_kmers(row, possible_kmers):\n",
    "    n_kmers = len(possible_kmers)\n",
    "    counts = np.zeros((1, n_kmers))\n",
    "    for j, kmer in enumerate(possible_kmers):\n",
    "        counts[0, j] = f\"{row.sequence.count(kmer) / len(row.sequence):.5f}\"\n",
    "    return pd.concat([row, pd.Series(counts[0], index=possible_kmers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_dirs = os.listdir(\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/\")\n",
    "possible_kmers = [\"\".join(x) for x in itertools.product(\"ATCG\", repeat=6)]\n",
    "\n",
    "for rbp in tqdm(rbp_dirs):\n",
    "    out_kmers, out_lsgkm = [], []\n",
    "    _dir = f\"4_all_motifScan/{rbp}\"\n",
    "\n",
    "    fasta_ctrl = f\"{_dir}/CTRL/1_seq_extraction/{rbp}_sequences_fixed_at_5000bp.fa\"\n",
    "    ctrl_df_ss = pd.read_csv(f\"{_dir}/CTRL/1_seq_extraction/{rbp}_sequences_ss_idx_fixed_at_5000bp.tsv\", sep=\"\\t\")\n",
    "    ctrl_df_ss['seq_id'] = ctrl_df_ss.header + \"_\"  + ctrl_df_ss.tx_id\n",
    "        \n",
    "    fasta_kd = f\"{_dir}/KD/1_seq_extraction/{rbp}_sequences_fixed_at_5000bp.fa\"\n",
    "    kd_df_ss = pd.read_csv(f\"{_dir}/KD/1_seq_extraction/{rbp}_sequences_ss_idx_fixed_at_5000bp.tsv\", sep=\"\\t\")\n",
    "    kd_df_ss['seq_id'] = kd_df_ss.header + \"_\"  + kd_df_ss.tx_id\n",
    "\n",
    "    for i, g in enumerate(['kd', 'ctrl']):\n",
    "        if i == 0:\n",
    "            data = fasta_kd\n",
    "            ss = kd_df_ss\n",
    "        else:\n",
    "            data = fasta_ctrl\n",
    "            ss = ctrl_df_ss\n",
    "\n",
    "        df = pd.DataFrame.from_dict(fasta_to_dict(data), orient='index').reset_index().rename(columns={'index': 'seq_id', 0: 'sequence'})\n",
    "        df = df.merge(PAIRED_DATASETS[['seq_id', 'target_coordinates', 'rbp_name', 'exon_group', 'dPSI', 'pred']], on=['seq_id']).rename(columns={'pred': 'spliceai_pred'})\n",
    "        df = df[df.rbp_name == rbp]\n",
    "        df = df.apply(_trim_seq, ss_df=ss, axis=1)\n",
    "        df = df.apply(_count_kmers, possible_kmers=possible_kmers, axis=1, result_type='expand')\n",
    "\n",
    "        cols = df.columns.tolist()\n",
    "        cols_to_move = ['exon_group', 'dPSI', 'spliceai_pred']\n",
    "        cols = [col for col in cols if col not in cols_to_move] + cols_to_move\n",
    "        df = df[cols]\n",
    "        out_kmers.append(df.drop(columns=['sequence']))\n",
    "        out_lsgkm.append(df.drop(columns=possible_kmers))\n",
    "\n",
    "    pd.concat(out_kmers).to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_kmers.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)\n",
    "    pd.concat(out_lsgkm).to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_full_seqs.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate input for ls-gkm for regression (predict spliceAI score) and classification (predict exon group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seqs = glob.glob(f\"../data/3_paired_datasets_tabular_to_ML//*_full_seqs.tsv.gz\")\n",
    "for dt in full_seqs:\n",
    "    data = pd.read_csv(dt,sep=\"\\t\")\n",
    "    rbp_name = data.rbp_name.iloc[0]\n",
    "    data['seq_id'] = data['seq_id'].apply(lambda x: \">\" + x)\n",
    "    outdir = f\"4_all_gappedKmers/{rbp_name}\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    os.makedirs(f\"{outdir}/regr\", exist_ok=True)\n",
    "    os.makedirs(f\"{outdir}/clf\", exist_ok=True)\n",
    "    kd = data[data.exon_group == \"KD\"]\n",
    "    ctrl = data[data.exon_group == \"CTRL\"]\n",
    "    kd[['seq_id', 'sequence']].to_csv(f\"{outdir}/clf/positive.fa\", sep=\"\\n\", index=False, header=False)\n",
    "    ctrl[['seq_id', 'sequence']].to_csv(f\"{outdir}/clf/negative.fa\", sep=\"\\n\", index=False, header=False)\n",
    "    data[['seq_id', 'sequence']].to_csv(f\"{outdir}/regr/seqs.fa\", sep=\"\\n\", index=False, header=False)\n",
    "    data.spliceai_pred.to_csv(f\"{outdir}/regr/spliceai_pred.txt\", sep=\"\\n\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3a7fa92aee0c575de82720ff7c994c61c7be9ffd1c939079d837777cbd42d86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ml_genomics': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
