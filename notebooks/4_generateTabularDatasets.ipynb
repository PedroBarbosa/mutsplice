{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count motif occurrences across datasets and generate tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently than MutSplice pipeline, that targeted motif of the RBP of interest, we now scan all motifs over all paired datasets to generate motif occurrences that can be used for machine learning. In addition, we also generate tabular datasets of k-mer-based occurrences, which serves as a unbiased approach to distinguish exon groups based on patterns found in sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(font_scale=1)\n",
    "from plotnine import *\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "tqdm.pandas()\n",
    "from mutsplice.datasets.tabular_dataset import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRED_DATASETS = pd.read_csv(\"/home/pbarbosa/git_repos/mutsplice/data/2_paired_datasets/ALL_data.tsv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLICEAI_PREDS = pd.read_csv(\"/home/pbarbosa/git_repos/mutsplice/notebooks/1_SpliceAI/4_datasets/encode_sequences_fixed_at_5000bp_output.tsv.gz\", sep=\"\\t\")\n",
    "SPLICEAI_PREDS['pred'] = SPLICEAI_PREDS[['ref_donor_cassette', 'ref_acceptor_cassette']].mean(axis=1)\n",
    "#SPLICEAI_PREDS = SPLICEAI_PREDS[['seq_id', 'target_coordinates', 'pred']]\n",
    "SPLICEAI_PREDS['transcript_id'] = SPLICEAI_PREDS.seq_id.str.split(\"_\").str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 18:15:13.866790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 18:15:14.513067: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-20 18:15:14.513148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-20 18:15:14.513154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from gtfhandle.utils import file_to_bed_df\n",
    "from mutsplice.datasets.mutsplice_pipeline import MutSplicePipeline\n",
    "\n",
    "def runMutSplice_justMotifScan(df, rbp_name: str, exon_group: str, motif_source: str, motif_search: str):\n",
    "    GTF_CACHE = \"/home/pbarbosa/data/genomes/hg38/gtf_cache_gencode/\"\n",
    "    OUT_DIR = f\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/{rbp_name}/\"\n",
    "    FASTA = \"/home/pbarbosa/data/genomes/hg38/GRCh38.primary_assembly.genome.fa\"\n",
    "\n",
    "    kwargs = {\n",
    "        \"gtf_cache\": GTF_CACHE,\n",
    "        \"fasta\": FASTA,\n",
    "        \"out_dir\": f\"{OUT_DIR}{exon_group}\",\n",
    "        \"outbasename\": f\"{rbp_name}\",\n",
    "        \"subset_rbps\": \"encode\",\n",
    "        \"motif_source\": motif_source,\n",
    "        \"motif_search\": motif_search,\n",
    "        \"pvalue_threshold\": 0.00002,\n",
    "        \"min_nuc_probability\": 0.15,\n",
    "        \"use_full_sequence\": False,\n",
    "        \"spliceai_final_results\": None\n",
    "    }\n",
    "    bed_df = file_to_bed_df(df, is_0_based=False, header=0, col_index=0)\n",
    "\n",
    "    MutSplicePipeline(\n",
    "        bed_df,\n",
    "        do_gtf_queries=True,\n",
    "        do_motif_scanning=True,\n",
    "        do_mutations=False,\n",
    "        run_spliceai=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_single_RBP(group, exon_group: str, motif_source: str, motif_search: str):\n",
    "    try:\n",
    "        rbp_name = group.iloc[0].rbp_name\n",
    "        runMutSplice_justMotifScan(\n",
    "            group,\n",
    "            rbp_name=rbp_name,\n",
    "            exon_group=exon_group,\n",
    "            motif_source=motif_source,\n",
    "            motif_search=motif_search,\n",
    "        )\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Caught ValueError for {rbp_name}: {ve}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knockdown exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KD_data = PAIRED_DATASETS[PAIRED_DATASETS.exon_group == \"KD\"]\n",
    "KD_data.groupby(\"rbp_name\").apply(\n",
    "    process_single_RBP, exon_group=\"KD\", motif_source=\"ATtRACT\", motif_search=\"fimo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control exons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctrl_data = PAIRED_DATASETS[PAIRED_DATASETS.exon_group == \"CTRL\"]\n",
    "Ctrl_data.groupby(\"rbp_name\").apply(\n",
    "    process_single_RBP,\n",
    "    exon_group=\"CTRL\",\n",
    "    motif_source=\"ATtRACT\",\n",
    "    motif_search=\"fimo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on motif occurrences (total and per location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_on = ['target_coordinates', 'transcript_id']\n",
    "PAIRED_DATASETS = PAIRED_DATASETS.merge(SPLICEAI_PREDS, on=merge_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'subset_rbps': 'encode_in_attract', \n",
    "          'motif_source': 'attract'}\n",
    "rbp_dirs = (os.listdir(\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/\"))\n",
    "cols_to_drop = [\"pred\", \"transcript_id\", \"Strand\", \"gene_name\", \"paired_with\"]\n",
    "to_drop_ending_with = [\"downstream_2\", \"upstream_2\"]\n",
    "to_drop_starting_with = [\"ref_acceptor\", \"ref_donor\"]\n",
    "\n",
    "for rbp in rbp_dirs:\n",
    "    _dir = f\"4_all_motifScan/{rbp}\"\n",
    "\n",
    "    data_kd = PAIRED_DATASETS[(PAIRED_DATASETS.rbp_name == rbp) & (PAIRED_DATASETS.exon_group == \"KD\")]\n",
    "    data_ctrl = PAIRED_DATASETS[(PAIRED_DATASETS.rbp_name == rbp) & (PAIRED_DATASETS.exon_group == \"CTRL\")]\n",
    "\n",
    "    for granularity, tag in {'motif': 'motifs', 'per_location': 'motifs_per_loc'}.items():\n",
    "        out = []\n",
    "    \n",
    "        for g_name, _data in {\"KD\": data_kd, \"CTRL\": data_ctrl}.items():\n",
    "        \n",
    "            td = TabularDataset(_data, \n",
    "                outdir=f\"{_dir}/{g_name}\", \n",
    "                granularity=granularity,\n",
    "                normalize_by_length=True,\n",
    "                **kwargs)\n",
    "            \n",
    "            td.data = td.data.drop(columns=cols_to_drop)\n",
    "            cols_to_keep = [col for col in td.data.columns if not any([col.endswith(ending) for ending in to_drop_ending_with]) and not any([col.startswith(start) for start in to_drop_starting_with])]\n",
    "            td.data = td.data[cols_to_keep]\n",
    "            out.append(td.data)\n",
    "        \n",
    "        df = pd.concat(out)\n",
    "        df.rename(columns={'average_cassette_strength': 'spliceai_pred'}, inplace=True)\n",
    "        cols = df.columns.tolist()\n",
    "        cols_to_move = ['exon_group', 'dPSI', 'spliceai_pred']\n",
    "        cols = [col for col in cols if col not in cols_to_move] + cols_to_move\n",
    "        df = df[cols]\n",
    "        df.to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_{tag}.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on k-mer occurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtfhandle.utils import fasta_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trim_seq(row, ss_df):\n",
    "    ss_idx = ss_df[ss_df.seq_id == row.seq_id].iloc[0]\n",
    "    start = ss_idx.acceptor_idx.split(\";\")[0]\n",
    "    if start == \"<NA>\":\n",
    "        start = 0\n",
    "    else:\n",
    "        start = int(start)\n",
    "    end = ss_idx.donor_idx.split(\";\")[2]\n",
    "    if end == \"<NA>\":\n",
    "        end = len(row.sequence)\n",
    "    else:\n",
    "        end = int(end)\n",
    "    \n",
    "    row['sequence'] = row['sequence'][start:end]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_kmers(row, possible_kmers):\n",
    "    n_kmers = len(possible_kmers)\n",
    "    counts = np.zeros((1, n_kmers))\n",
    "    for j, kmer in enumerate(possible_kmers):\n",
    "        counts[0, j] = f\"{row.sequence.count(kmer) / len(row.sequence):.5f}\"\n",
    "    return pd.concat([row, pd.Series(counts[0], index=possible_kmers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_dirs = os.listdir(\"/home/pbarbosa/git_repos/mutsplice/notebooks/4_all_motifScan/\")\n",
    "possible_kmers = [\"\".join(x) for x in itertools.product(\"ATCG\", repeat=5)]\n",
    "\n",
    "out_kmers, out_lsgkm = [], []\n",
    "\n",
    "for rbp in tqdm(rbp_dirs):\n",
    "    _dir = f\"4_all_motifScan/{rbp}\"\n",
    "\n",
    "    fasta_ctrl = f\"{_dir}/CTRL/1_seq_extraction/{rbp}_sequences_fixed_at_5000bp.fa\"\n",
    "    ctrl_df_ss = pd.read_csv(f\"{_dir}/CTRL/1_seq_extraction/{rbp}_sequences_ss_idx_fixed_at_5000bp.tsv\", sep=\"\\t\")\n",
    "    ctrl_df_ss['seq_id'] = ctrl_df_ss.header + \"_\"  + ctrl_df_ss.tx_id\n",
    "        \n",
    "    fasta_kd = f\"{_dir}/KD/1_seq_extraction/{rbp}_sequences_fixed_at_5000bp.fa\"\n",
    "    kd_df_ss = pd.read_csv(f\"{_dir}/KD/1_seq_extraction/{rbp}_sequences_ss_idx_fixed_at_5000bp.tsv\", sep=\"\\t\")\n",
    "    kd_df_ss['seq_id'] = kd_df_ss.header + \"_\"  + kd_df_ss.tx_id\n",
    "\n",
    "    for i, g in enumerate(['kd', 'ctrl']):\n",
    "        if i == 0:\n",
    "            data = fasta_kd\n",
    "            ss = kd_df_ss\n",
    "        else:\n",
    "            data = fasta_ctrl\n",
    "            ss = ctrl_df_ss\n",
    "\n",
    "        df = pd.DataFrame.from_dict(fasta_to_dict(data), orient='index').reset_index().rename(columns={'index': 'seq_id', 0: 'sequence'})\n",
    "        df = df.merge(PAIRED_DATASETS[['seq_id', 'target_coordinates', 'rbp_name', 'exon_group', 'dPSI', 'pred']], on=['seq_id']).rename(columns={'pred': 'spliceai_pred'})\n",
    "        df = df[df.rbp_name == rbp]\n",
    "        df = df.apply(_trim_seq, ss_df=ss, axis=1)\n",
    "        df = df.apply(_count_kmers, possible_kmers=possible_kmers, axis=1, result_type='expand')\n",
    "        cols = df.columns.tolist()\n",
    "        cols_to_move = ['exon_group', 'dPSI', 'spliceai_pred']\n",
    "        cols = [col for col in cols if col not in cols_to_move] + cols_to_move\n",
    "        df = df[cols]\n",
    "        out_kmers.append(df.drop(columns=['sequence']))\n",
    "        out_lsgkm.append(df.drop(columns=possible_kmers))\n",
    "\n",
    "    pd.concat(out_kmers).to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_kmers.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)\n",
    "    pd.concat(out_lsgkm).to_csv(f\"../data/3_paired_datasets_tabular_to_ML/{rbp}_full_seqs.tsv.gz\", sep=\"\\t\", compression='gzip', index=False)    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3a7fa92aee0c575de82720ff7c994c61c7be9ffd1c939079d837777cbd42d86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ml_genomics': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
